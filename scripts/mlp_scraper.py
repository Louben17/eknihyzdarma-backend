#!/usr/bin/env python3
"""
MLP OAI-PMH Scraper
====================
Stahuje metadata volnÄ› dostupnÃ½ch e-knih z MÄ›stskÃ© knihovny Praha (MLP).
VyuÅ¾Ã­vÃ¡ OAI-PMH protokol, vÃ½stup je JSON soubor s metadaty a linky ke staÅ¾enÃ­.

SpuÅ¡tÄ›nÃ­:
    python mlp_scraper.py            # 20 knih (test)
    python mlp_scraper.py --limit 100
    python mlp_scraper.py --limit 0  # vÅ¡echny (~3400)
    python mlp_scraper.py --output moje_knihy.json
"""

import argparse
import json
import sys
import time
import unicodedata
import xml.etree.ElementTree as ET
from typing import Optional

import requests

# Oprava Windows cp1250 encoding â€“ nutnÃ© pro ÄeskÃ© znaky a emoji v konzoli
if hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
if hasattr(sys.stderr, "reconfigure"):
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")

# OAI-PMH endpoint MLP
OAI_BASE = "http://web2.mlp.cz/cgi/oai"
OAI_SET = "ebook"
OAI_PREFIX = "marc21"

# XML namespaces
NS_OAI = "http://www.openarchives.org/OAI/2.0/"
NS_MARC = "http://www.loc.gov/MARC21/slim"

# FormÃ¡ty ke staÅ¾enÃ­ (ext â†’ label)
FORMAT_MAP = {
    "epub": "EPUB",
    "pdf": "PDF",
    "prc": "PRC",
    "mobi": "MOBI",
    "txt": "TXT",
    "html": "HTML",
    "rtf": "RTF",
    "pdb": "PDB",
}

# PrioritnÃ­ formÃ¡ty pro nÃ¡Å¡ web (ostatnÃ­ ignorujeme pro pÅ™ehlednost)
PRIORITY_FORMATS = {"epub", "pdf", "prc", "mobi"}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MARC21 helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_subfield(record: ET.Element, tag: str, code: str) -> Optional[str]:
    """VrÃ¡tÃ­ prvnÃ­ hodnotu subfieldu z MARC21 zÃ¡znamu."""
    for field in record.findall(f".//{{{NS_MARC}}}datafield[@tag='{tag}']"):
        sf = field.find(f"{{{NS_MARC}}}subfield[@code='{code}']")
        if sf is not None and sf.text:
            return sf.text.strip()
    return None


def get_all_subfields(record: ET.Element, tag: str, code: str) -> list[str]:
    """VrÃ¡tÃ­ vÅ¡echny hodnoty subfieldu."""
    results = []
    for field in record.findall(f".//{{{NS_MARC}}}datafield[@tag='{tag}']"):
        sf = field.find(f"{{{NS_MARC}}}subfield[@code='{code}']")
        if sf is not None and sf.text:
            results.append(sf.text.strip())
    return results


def parse_856_fields(record: ET.Element) -> tuple[list[dict], Optional[str]]:
    """
    Zpracuje vÅ¡echna pole 856 (URL linky).
    VrÃ¡tÃ­ (seznam download linkÅ¯, URL obÃ¡lky).
    """
    links = []
    cover_url = None

    for field in record.findall(f".//{{{NS_MARC}}}datafield[@tag='856']"):
        url_el = field.find(f"{{{NS_MARC}}}subfield[@code='u']")
        label_el = field.find(f"{{{NS_MARC}}}subfield[@code='z']")

        if url_el is None or not url_el.text:
            continue

        url = url_el.text.strip()
        label = label_el.text.strip() if label_el is not None else ""

        # Detekce obÃ¡lky
        if url.endswith(".jpg") or "obÃ¡lka" in label.lower() or "obalka" in label.lower():
            cover_url = url
            continue

        # Detekce formÃ¡tu
        ext = url.rsplit(".", 1)[-1].lower() if "." in url else ""
        if ext in FORMAT_MAP:
            links.append({
                "url": url,
                "format": FORMAT_MAP[ext],
                "ext": ext,
                "label": label,
            })

    # SeÅ™adit podle priority (epub prvnÃ­)
    priority_order = ["epub", "pdf", "prc", "mobi", "html", "txt", "rtf", "pdb"]
    links.sort(key=lambda x: priority_order.index(x["ext"]) if x["ext"] in priority_order else 99)

    return links, cover_url


def slugify(text: str) -> str:
    """PÅ™evede text na URL slug."""
    text = unicodedata.normalize("NFKD", text)
    text = "".join(c for c in text if not unicodedata.combining(c))
    text = text.lower()
    text = "".join(c if c.isalnum() or c == " " else "-" for c in text)
    text = "-".join(text.split())
    text = text.strip("-")
    return text[:200]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ZpracovÃ¡nÃ­ zÃ¡znamu
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_record(record_el: ET.Element) -> Optional[dict]:
    """Zpracuje jeden OAI-PMH zÃ¡znam, vrÃ¡tÃ­ dict nebo None."""

    # Zkontrolujeme, zda zÃ¡znam nenÃ­ smazÃ¡n
    header = record_el.find(f"{{{NS_OAI}}}header")
    if header is not None and header.get("status") == "deleted":
        return None

    marc = record_el.find(f".//{{{NS_MARC}}}record")
    if marc is None:
        return None

    # OAI identifikÃ¡tor
    id_el = header.find(f"{{{NS_OAI}}}identifier") if header is not None else None
    oai_id = id_el.text.strip() if id_el is not None else None

    # NÃ¡zev â€“ MARC 245 $a (hlavnÃ­) + $b (vedlejÅ¡Ã­)
    title_a = get_subfield(marc, "245", "a") or ""
    title_b = get_subfield(marc, "245", "b") or ""
    title = (title_a.rstrip("/ :") + (" " + title_b.rstrip("/ :") if title_b else "")).strip()
    if not title:
        return None

    # Autor â€“ MARC 100 $a (primÃ¡rnÃ­), nebo 700 $a (pÅ™idanÃ½)
    author = get_subfield(marc, "100", "a") or get_subfield(marc, "700", "a")
    if author:
        author = author.rstrip(",. ").strip()

    # Popis â€“ MARC 520 $a
    description = get_subfield(marc, "520", "a")

    # Rok vydÃ¡nÃ­ â€“ z MARC 008 (znaky 7-10)
    year = None
    ctrl008 = marc.find(f".//{{{NS_MARC}}}controlfield[@tag='008']")
    if ctrl008 is not None and ctrl008.text and len(ctrl008.text) >= 11:
        year_str = ctrl008.text[7:11].strip()
        if year_str.isdigit():
            year = int(year_str)

    # TÃ©mata â€“ MARC 650 $a
    topics = get_all_subfields(marc, "650", "a")
    topics = [t.rstrip(".,;") for t in topics if t]

    # Linky ke staÅ¾enÃ­ a obÃ¡lka
    links, cover_url = parse_856_fields(marc)

    # Filtrujeme jen prioritnÃ­ formÃ¡ty pro nÃ¡Å¡ web
    main_links = [lnk for lnk in links if lnk["ext"] in PRIORITY_FORMATS]

    if not main_links:
        return None  # Kniha bez staÅ¾itelnÃ½ch formÃ¡tÅ¯ â€“ pÅ™eskoÄÃ­me

    return {
        "mlpId": oai_id,
        "title": title,
        "slug": slugify(title),
        "author": author,
        "description": description,
        "year": year,
        "topics": topics,
        "coverUrl": cover_url,
        "links": main_links,  # jen EPUB, PDF, PRC, MOBI
        "allLinks": links,    # kompletnÃ­ seznam pro referenci
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OAI-PMH strÃ¡nkovÃ¡nÃ­
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_all_records(limit: int = 20, delay: float = 1.0) -> list[dict]:
    """
    StÃ¡hne zÃ¡znamy z OAI-PMH endpointu.
    limit=0 znamenÃ¡ stÃ¡hnout vÅ¡e.
    """
    books = []
    params = {
        "verb": "ListRecords",
        "set": OAI_SET,
        "metadataPrefix": OAI_PREFIX,
    }
    resumption_token = None
    page = 0

    while True:
        page += 1
        print(f"  StrÃ¡nka {page} | staÅ¾eno: {len(books)}", end="")
        if limit > 0:
            print(f" / {limit}", end="")
        print()

        if resumption_token:
            params = {"verb": "ListRecords", "resumptionToken": resumption_token}

        try:
            resp = requests.get(OAI_BASE, params=params, timeout=30)
            resp.raise_for_status()
        except requests.RequestException as e:
            print(f"\n  âœ— Chyba pÅ™i stahovÃ¡nÃ­: {e}")
            break

        try:
            root = ET.fromstring(resp.content)
        except ET.ParseError as e:
            print(f"\n  âœ— Chyba XML parsovÃ¡nÃ­: {e}")
            break

        list_records = root.find(f"{{{NS_OAI}}}ListRecords")
        if list_records is None:
            print("  âœ— ListRecords element nenalezen")
            break

        for record_el in list_records.findall(f"{{{NS_OAI}}}record"):
            book = parse_record(record_el)
            if book:
                books.append(book)
                print(f"    [{len(books):>4}] {book['title'][:60]:<60} â€“ {book.get('author', 'â€”')}")

            if limit > 0 and len(books) >= limit:
                print(f"\n  âœ“ DosaÅ¾en limit {limit} knih")
                return books

        # Resumption token pro dalÅ¡Ã­ strÃ¡nku
        token_el = list_records.find(f"{{{NS_OAI}}}resumptionToken")
        if token_el is not None and token_el.text and token_el.text.strip():
            resumption_token = token_el.text.strip()
            time.sleep(delay)
        else:
            print("  âœ“ Å½Ã¡dnÃ© dalÅ¡Ã­ strÃ¡nky")
            break

    return books


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HlavnÃ­ program
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="MLP OAI-PMH Scraper")
    parser.add_argument("--limit", type=int, default=20,
                        help="PoÄet knih ke staÅ¾enÃ­ (0 = vÅ¡e, default: 20)")
    parser.add_argument("--output", default="mlp_books.json",
                        help="VÃ½stupnÃ­ JSON soubor (default: mlp_books.json)")
    parser.add_argument("--delay", type=float, default=1.0,
                        help="Pauza mezi strÃ¡nkami v sekundÃ¡ch (default: 1.0)")
    args = parser.parse_args()

    print("=" * 60)
    print("  MLP E-books Scraper")
    print("  Zdroj: MÄ›stskÃ¡ knihovna Praha (OAI-PMH)")
    print("=" * 60)
    if args.limit == 0:
        print(f"  ReÅ¾im: stÃ¡hnout VÅ ECHNY knihy")
    else:
        print(f"  Limit: {args.limit} knih")
    print(f"  VÃ½stup: {args.output}")
    print()

    books = fetch_all_records(limit=args.limit, delay=args.delay)

    with open(args.output, "w", encoding="utf-8") as f:
        json.dump(books, f, ensure_ascii=False, indent=2)

    print()
    print("=" * 60)
    print(f"  âœ“ UloÅ¾eno {len(books)} knih â†’ {args.output}")

    # Statistiky
    with_cover = sum(1 for b in books if b.get("coverUrl"))
    with_desc = sum(1 for b in books if b.get("description"))
    formats = {}
    for b in books:
        for lnk in b.get("links", []):
            formats[lnk["ext"]] = formats.get(lnk["ext"], 0) + 1

    print(f"  ğŸ“¸ S obÃ¡lkou:   {with_cover}/{len(books)}")
    print(f"  ğŸ“ S popisem:   {with_desc}/{len(books)}")
    print(f"  ğŸ“ FormÃ¡ty:     {dict(sorted(formats.items(), key=lambda x: -x[1]))}")
    print("=" * 60)

    if books:
        print("\n  UkÃ¡zka prvnÃ­ knihy:")
        b = books[0]
        print(f"    NÃ¡zev:   {b['title']}")
        print(f"    Autor:   {b.get('author', 'â€”')}")
        print(f"    ObÃ¡lka:  {b.get('coverUrl', 'â€”')}")
        print(f"    Linky:   {[f['format'] for f in b['links']]}")
        if b.get("description"):
            print(f"    Popis:   {b['description'][:120]}...")


if __name__ == "__main__":
    main()
